\section*{Chapter 1}

\section*{Section 1: The Vector Space $\mathbb{R}^n$}

\subsection*{Exercise 1.1}

Let $S$ be the set in question. Then, if $\mathbf{x}=(x_1,\dots,x_n)\in S$ and $\mathbf{y}=(y_1,\dots,y_n)\in S$, we have
\begin{gather*}
    a_1x_1 + \dots + a_nx_n = 0 \\
    a_1y_1 + \dots a_ny_n = 0.
\end{gather*}

Adding these, it is clear that $\mathbf{x}+\mathbf{y}$ must belong to $S$. Finally, since $a_1(cx_1) + \dots + a_n(cx_n) = c(a_1x_1+\dots+a_nx_n) = 0$ for any real number $c$, the vector $c\mathbf{x}$ also belongs to $S$, and so it is a subspace of $\mathbb{R}^n$.

\subsection*{Exercise 1.2}

Let $\mathbf{x},\mathbf{y}\in V\cap W$ (observe that $\mathbf{x}$ and $\mathbf{y}$ are in both $V$ and $W$). Then, $\mathbf{x}+\mathbf{y}\in V$, since $V$ is a subspace, and similarly, $\mathbf{x}+\mathbf{y}\in W$, so that $\mathbf{x}+\mathbf{y}\in V\cap W$. By the same reasoning, for any real number $c$, the vector $c\mathbf{x}$ is also in both $V$ and $W$, so that $c\mathbf{x}\in V\cap W$.

\subsection*{Exercise 1.3}

Let $\mathbf{x},\mathbf{y}\in V+W$, with $\mathbf{x}=v_1 + w_1$ and $\mathbf{y} = v_2 + w_2$. Then the vector $\mathbf{x}+\mathbf{y}=(v_1+w_1)+(v_2+w_2) = (v_1+v_2)+(w_1+w_2)$ must also be in $V+W$ since $v_1+v_2\in V$ and $w_1+w_2\in W$ (note that the last equality holds since vector addition is commutative). Similarly, the vector $c\mathbf{x} = cv_1 + cw_1$ is also in $V+W$ since $cv_1\in V$ and $cw_1\in W$.

\subsection*{Exercise 1.4}

Let $v_1,v_2\in V$, with $v_1 = (x_1, y_1, z_1)$ and $v_2 = (x_2, y_2, z_2)$. Then
\begin{gather*}
    (x_1 + x_2) + 2(y_1 + y_2) = (x_1 + 2y_1) + (x_2 + 2y_2) = 0\\
    (x_1 + x_2) + (y_1 + y_2) = (x_1+y_1) + (x_2+y_2) = 3z_1 + 3z_2 = 3(z_1+z_2),
\end{gather*}
which shows that $v_1+v_2\in V$. Similarly, since $cx_1 + 2(cy_1) = c(x_1+2y_1)=0$ and $cx_1 + cy_1 - 3(cz_1) = c(x_1+y_1-3z_1) = 0$, the vector $cv_1\in V$ as well.

\subsection*{Exercise 1.5}

First note that the sum of any differentiable functions $f,g: [0,1]\rightarrow \mathbb{R}$ is itself a differentiable real-valued function on $[0,1]$, as is the function $cf$ for any real number $c$. If $f$ and $g$ have the property that $f(0)=f(1)=0$ and $g(0)=g(1)=0$, then $(f+g)(0) = f(0)+g(0) = 0$ and $(f+g)(1) = f(1)+g(1) = 0$, so that $f+g$ has the property as well. Similarly, for the function $cf$, $(cf)(0)=cf(0)=0$ and $(cf)(1)=cf(1)=0$.\\

If $f(1)$ was $1$ instead of $0$, then for any real number $c$ (apart from $1$), $(cf)(1) = cf(1)=c\neq 1$, so the set would not be closed under scalar multiplication.

\subsection*{Exercise 1.1}

\section*{Section 2: Subspaces of $\mathbb{R}^n$}

\subsection*{Exercise 2.1}

Without a loss of generality (since we may reorder), suppose $v_1 = \mathbf{0}$. Then the linear combination $1v_1 + 0v_2 + 0v_3 + \dots + 0v_k$ sum to $\mathbf{0}$, and not all coefficients are zero making the set of $v_i$ linearly dependent.\\

Similarly, suppose $v_1, v_2, \dots, v_r$ are linearly dependent, with $r\leq k$. This assures us of the existence of scalars $x_i$ which are not all zero so that $x_1v_1 + \dots + x_rv_r = \mathbf{0}$. But then the linear combination $x_1v_1 + \dots + x_rv_r + 0v_{r+1} + \dots + 0v_k$ sum to $\mathbf{0}$, and not all coefficients are zero making the set of $v_i$ linearly dependent.

\subsection*{Exercise 2.2}

We will investigate the linear independence of each set of vectors since Theorem $2.4$ tells us that a set of $n$ linearly independent vectors constitute a basis of a vector space with dimension $n$. For the set of vectors $v_1, \dots v_n$, if the equation $a_1v_1 + \dots a_nv_n=\mathbf{0}$ only has the trivial solution $a_i = 0$ for all $i$, then the vectors are a basis. If not, then they are not a basis. 

\subsubsection*{(a)}

\begin{gather*}
    a_1
    \begin{bmatrix}
    1\\
    0
    \end{bmatrix}
    +a_2
    \begin{bmatrix}
    1\\
    1
    \end{bmatrix}
    =
    \begin{bmatrix}
    a_1+a_2\\
    a_2
    \end{bmatrix}
    =
    \begin{bmatrix}
    0\\
    0
    \end{bmatrix}\\
    \iff \\
    a_1+a_2=0\\
    a_2=0\\
    \iff \\
    a_1=a_2=0.
\end{gather*}

\subsubsection*{(b)}

\subsubsection*{(c)}

\subsubsection*{(d)}

\subsection*{Exercise 2.3}

Observe that

\[
\begin{bmatrix}
    1\\
    1\\
    1\\
    1
\end{bmatrix}
=
1\begin{bmatrix}
    0\\
    1\\
    0\\
    1
\end{bmatrix}
+
1\begin{bmatrix}
    1\\
    0\\
    1\\
    0
\end{bmatrix}.
\]

Thus $V=\text{span}\left( [0,1,0,1], [1,0,1,0] \right)$, which has dimension $2$, since the two are linearly independent.

\subsection*{Exercise 2.4}



\subsection*{Exercise 2.5}

If there were no such vectors $v_{k+1}, \dots , v_{n}$ so that $v_1, \dots, v_n$ were all linearly independent, then the dimension of $V$ must be $k$, since it is the largest number of linearly independent vectors which $V$ contains. But $k<n=\text{dim}V$ so this cannot be true.

\subsection*{Exercise 2.6}

Let the vectors $\textbf{a\textsubscript{j}}$ be as in the text. Then the hypothesis is equivalent to the statement that $ x_1\textbf{a\textsubscript{1}} + \dots + x_n\textbf{a\textsubscript{n}}=\textbf{0} $ has only the trivial solution. Thus the vectors $a_j$ are linearly independent and so they constitute a \textit{unique} basis for $\mathbb{R}^n$ by Theorem $2.4$. This means they span $\mathbb{R}^n$ uniquely, and so the equation $x_1\textbf{a\textsubscript{1}} + \dots + x_n\textbf{a\textsubscript{n}}=\textbf{b}$ has a unique solution for each $\textbf{b}\in\mathbb{R}^n$.

\subsection*{Exercise 2.7}

Let $\mathbf{r}=$

\section*{Section 3: Inner Products and Orthogonality}

\subsection*{Exercise 3.1}

Since the inner product is bilinear (SP $3$), we have that $\left< \mathbf{0}, \mathbf{0} \right> = \left< \mathbf{0} + \mathbf{0}, \mathbf{0} \right> = \left< \mathbf{0}, \mathbf{0} \right> + \left< \mathbf{0}, \mathbf{0} \right>$. Subtracting gives $\left< \mathbf{0}, \mathbf{0} \right>=0$.

\subsection*{Exercise 3.2}
\subsection*{Exercise 3.3}
\subsection*{Exercise 3.4}
\subsection*{Exercise 3.5}
\subsection*{Exercise 3.6}
\subsection*{Exercise 3.7}
\subsection*{Exercise 3.8}
\subsection*{Exercise 3.9}
\subsection*{Exercise 3.10}
\subsection*{Exercise 3.11}
\subsection*{Exercise 3.12}